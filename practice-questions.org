#+TITLE: Practise Questions And Solutions-- TSAF
#+AUTHOR: @@latex:\\@@ https://github.com/BonfaceKilz/dsa8202-tsaf-questions
#+OPTIONS: toc:nil
#+LATEX_CLASS_OPTIONS: [a4paper]
#+OPTIONS: H:2 num:3 num:4
* Definitions
** General
*** State three conditions of weak stationarity for a time series process in lay language?
*** Define the autocorrelation function (ACF) for a stationary time series.
*** Describe, in general terms, the behavior you would expect to see for the estimated ACF computed from the set of observations $Y_t ..., Y_T$ generated by the random walk model.
*** The time series is read into an R data set called deaths and the following statements are issued to R.

#+begin_src R
> acf(diff(diff(deaths, 12), 1), 24)
> pacf(diff(diff(deaths, 12), 1), 24)
#+end_src
Describe in detail exactly what these statements do.

*** The following graphs are produced as a result of running the R statements above. Explain what kind of model structure you think that the graphs indicate is appropriate for modelling this series.

#+ATTR_LATEX: :width 1.1\textwidth
#+RESULTS:
file:ACF-STA-8203-TSAF.png

#+ATTR_LATEX: :width 1.1\textwidth
file:PACF-STA-8203-TSAF.png

*** Using operator notation, write down the complete model which should be fitted to the accident data series.

*** Show the implication of /de-trending a difference-stationary/ time series

*** Explain the different exponential smoothing models.
** AR/ AR(I)MA Models
*** Define what it means for a time series, $Y_t$ to be an AR(1) series

*** What conditions will ensure that an AR(1) series will be stationary and causal

*** Suppose that $Y_t$ is a stationary, causal AR (1) series.  Describe, as exactly as you can, the type of ARMA series which is produced by taking simple differences of $Y_t$

*** Does the equation $Y_t = \frac{1}{5}Y_{t-1} + \frac{4}{7}Y_{t-2} + \epsilon_t$ define a stationary, causal time series? Explain.
*** Write the general form of seasonal ARIMA model stating different parameters

*** In order to forecast the monthly unemployment rate series data, it was decided to difference the series twice; once at lag 1 and once at lag 12. Explain why such differencing is required and explain how the decision to difference with these particular lags may have been arrived at.
*** Explain the difference between autocorrelation function (ACF) and partial autocorrelation function (PACF) and state their use in time series analysis
*** State four major steps of developing ARMA(p, q) model and explain each step.

* Questions that require some Math
** General
*** Let a time series process:
\begin{align*}
X_t &= Y_t &\text{if t is even}\\
    &= Y_t + 1 &\text{if t is odd}
\end{align*}
**** Is Y_t stationary process?
**** Suggest a transformation to make the series stationary and prove that the transformed series is stationary.
*** Specify a typical Autoregressive (AR) Model and a Moving Average (MA) Model both of order one (1), and show by derivation the differences in the shapes of their autocorrelation functions at lag length j
*** Show the formulation for the Augmented Dickey Fuller (ADF) test for stationarity and discuss its novelty over the Dickey Fuller (DF) test as well as its weakness in dealing with some time series properties of data
*** Clearly show that differencing a trend stationary series introduces a unit root in the errors
** MA
*** Consider first-order moving average process of the form $Y_t = \epsilon_t + 0.75\epsilon_{t-1}$ where $\epsilon_t$ is a white noise series distributed with mean zero and constant variance $\sigma_\epsilon^ = 0.12$. Determine the autocorrelation at lag 1, $\rho(1)$
*** Derive the ACF for the MA (2) series generated by the scheme

#+begin_equation
Y_t = \phiY_{t-1} + w_t
#+end_equation

where $|\phi| < 1$ and $w_t$ is a white noise series
** AR/ AR(I)MA Models
*** Specify an ARMA(p,q) time series process and show that this model can display both stationarity and invertibility conditions
*** Consider the following ARMA (2,2) model. Establish if there are redundant parameters and whether the reduced model is stationary and invertible

#+begin_equation
X_t - 0.4 X_{t-1} - 0.45X_{t-2} = w_t + w_{t-1} + 0.25w_{t-2}
#+end_equation
*** Consider a model:
#+begin_equation
(1 - B)(1 - B^2)(1 - 0.43B^{12})X_t = (1 + 0.22B)(1 + 0.88B^{12})w_t
#+end_equation
Identify different components of the model and write the ARIMA form of the model.
*** The following parameter estimates were computed for seasonal ARIMA model based on the original data. Use the results to answer the questions that follow.

#+begin_src R
ele.arima <‐ arima(electricity, order=c(1,0,0), seasonal =list(order=c(2,1,0), period =12))
#+end_src

| *Parameter* | Estimate | Std. Error |
| AR(1)     |   0.2856 |     0.0642 |
| SAR(1)    |  -0.8598 |     0.0639 |
|-----------+----------+------------|
| SAR(2)    |  -0.2963 |     0.0667 |

**** Write the presented autoregressive model in the form of ARIMA (p, d, q) (P, D, Q) S
**** Write down an expression for the fitted model

*** The following cosine function can be used to model the seasonal pattern that might exist in the data. :noexport:
#+begin_equation
f(t) = \alpha cos[(wt) - \theta]
#+end_equation

Show how the model can be represented by both sine and cosine.


*** A time series model is fit to the deaths series and the following results and plots obtained.  Does the model fit well? Give reasons

|                                                                |            PARAM 1 |            PARAM 2 |
|----------------------------------------------------------------+--------------------+--------------------|
| Estimate                                                       |            -0.4264 |            -0.5584 |
| SE                                                             |             0.1226 |             0.1787 |
| 95% CI of estimate                                             | -0.6667 to -0.1861 | -0.9087 to -0.2082 |
$\sigma^2 = 99480$; Log Likelihood = -425.53; and AIC = 857.06

#+ATTR_LATEX: :width 1.1\textwidth
#+RESULTS:
file:afc-pacf-deaths.png

*** For the ARMA(1, 2) model $Y_t = 0.8Y_{t-1} + w_t + 0.7w_{t-1} + 0.6w_{t-2} show that$:
(i)$\rho(k) = 0.8\rho(k-1), \text{for } k \ge 3$ and (ii) $\rho(2) = (\frac{0.8\rho(1) + 0.6\alpha_w^2}{\gamma(0)})$

*** The oscillation data defined as the difference in barometric pressure was modelled by considering two possible, AR(2) and MA(1) on differenced data. The parameter estimates computed for the two models are presented below. Use the results to answer the questions that follow.
+-------------+-------------+--------------------+-----------+----------+--------------------+
| AR(2) Model                                    | MA(1) Model                                |
+-------------+-------------+--------------------+-----------+----------+--------------------+
|             |    Estimate | 95% CI             |           | Estimate | 95% CI             |
+-------------+-------------+--------------------+-----------+----------+--------------------+
| Intercept   |     -0.0050 |                    | Intercept |  -0.0051 |                    |
| AR1         |     -0.4064 | (-0.4884, -0.3243) | MA1       |  -0.3921 | (-0.4638, -0.3205) |
| AR2         |     -0.1649 | (-0.2469, -0.0829) |           |          |                    |
+-------------+-------------+--------------------+-----------+----------+--------------------+

**** Write each model in the form of ARIMA
**** Write each model for the differenced data taking Yt, to represent the differenced observations and wt the white noise for the differenced data.
**** It is often more convenient to express the models in terms of the original data, rather than the differenced data. Express each model in terms of the original data, Xt, rather than the differenced data, $Y_t$.
**** The Box-Ljung test was used to determine the model that best fit the data. The p-value for AR(2) was 0.080 and for MA(1) was 0.026. State the null and alternative hypothesis under the Box-Ljung test and the conclusion on the best fit.
